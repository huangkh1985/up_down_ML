"""
é¢„æµ‹æ—¶é—´çª—å£å¯¹æ¯”å®éªŒ
æµ‹è¯•ä¸åŒé¢„æµ‹å¤©æ•°ï¼ˆ1å¤©ã€3å¤©ã€5å¤©ã€10å¤©ï¼‰çš„å‡†ç¡®ç‡
"""

import pandas as pd
import numpy as np
import pickle
import os
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score
import matplotlib.pyplot as plt
import warnings

from utils.pattern_recognition import add_pattern_features

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False


def prepare_data_with_horizon(all_data, lookback_days=60, forecast_horizon=5):
    """
    å‡†å¤‡æŒ‡å®šé¢„æµ‹çª—å£çš„æ•°æ®
    """
    print(f"\nå‡†å¤‡{forecast_horizon}å¤©é¢„æµ‹æ•°æ®...")
    print("-"*60)
    
    all_X = []
    all_y = []
    
    for stock_code, df in all_data.items():
        if 'Bullish_Reversal' not in df.columns:
            df = add_pattern_features(df)
        
        df['Any_Reversal'] = ((df['Bullish_Reversal'] == 1) | 
                              (df['Bearish_Reversal'] == 1)).astype(int)
        
        # æå–ç‰¹å¾
        feature_columns = ['Close', 'Volume', 'RSI', 'MACD', 'ATR', 'MA20']
        available_features = [col for col in feature_columns if col in df.columns]
        
        for i in range(lookback_days, len(df) - forecast_horizon):
            # é¢„æµ‹æœªæ¥forecast_horizonå¤©çš„ä¿¡å·
            future_signal = df['Any_Reversal'].iloc[i + forecast_horizon]
            
            # æå–å‰lookback_dayså¤©çš„ç»Ÿè®¡ç‰¹å¾
            lookback_data = df.iloc[i-lookback_days:i]
            
            feature_dict = {}
            for col in available_features:
                if col in lookback_data.columns:
                    values = lookback_data[col].values
                    feature_dict[f'{col}_mean'] = np.mean(values)
                    feature_dict[f'{col}_std'] = np.std(values)
                    feature_dict[f'{col}_last'] = values[-1]
            
            all_X.append(feature_dict)
            all_y.append(int(future_signal))
    
    X = pd.DataFrame(all_X)
    y = pd.Series(all_y)
    
    print(f"  æ ·æœ¬æ•°: {len(X)}")
    print(f"  ä¿¡å·æ ·æœ¬: {y.sum()} ({y.sum()/len(y):.2%})")
    print(f"  ç‰¹å¾æ•°: {X.shape[1]}")
    
    return X, y


def test_single_horizon(all_data, forecast_horizon, lookback_days=60):
    """
    æµ‹è¯•å•ä¸ªé¢„æµ‹çª—å£çš„æ€§èƒ½
    """
    print(f"\n{'='*80}")
    print(f"æµ‹è¯•é¢„æµ‹çª—å£: {forecast_horizon}å¤©å")
    print(f"{'='*80}")
    
    try:
        # å‡†å¤‡æ•°æ®
        X, y = prepare_data_with_horizon(all_data, lookback_days, forecast_horizon)
        
        if len(X) < 100:
            print(f"âš ï¸ æ ·æœ¬æ•°è¿‡å°‘ ({len(X)})ï¼Œè·³è¿‡")
            return None
        
        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
        minority_ratio = y_train.value_counts().min() / y_train.value_counts().max()
        
        if minority_ratio < 0.3:
            try:
                from imblearn.over_sampling import SMOTE
                smote = SMOTE(random_state=42)
                X_train, y_train = smote.fit_resample(X_train, y_train)
                print(f"  ä½¿ç”¨SMOTEå¹³è¡¡æ•°æ®")
            except:
                pass
        
        # è®­ç»ƒæ¨¡å‹
        print(f"  è®­ç»ƒæ¨¡å‹...")
        model = RandomForestClassifier(
            n_estimators=200,
            max_depth=10,
            class_weight='balanced',
            random_state=42,
            n_jobs=-1
        )
        
        model.fit(X_train, y_train)
        
        # é¢„æµ‹
        y_pred = model.predict(X_test)
        
        # è¯„ä¼°
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, zero_division=0)
        recall = recall_score(y_test, y_pred, zero_division=0)
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
        
        print(f"\n  ç»“æœ:")
        print(f"    å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy:.2%})")
        print(f"    ç²¾ç¡®ç‡: {precision:.4f} ({precision:.2%})")
        print(f"    å¬å›ç‡: {recall:.4f} ({recall:.2%})")
        print(f"    F1åˆ†æ•°: {f1:.4f}")
        
        return {
            'forecast_horizon': forecast_horizon,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'samples': len(X),
            'signal_ratio': y.sum() / len(y),
            'test_samples': len(X_test)
        }
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def visualize_comparison(results_df):
    """
    å¯è§†åŒ–å¯¹æ¯”ç»“æœ
    """
    print(f"\nç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle('ä¸åŒé¢„æµ‹çª—å£æ€§èƒ½å¯¹æ¯”', fontsize=16, fontweight='bold')
    
    # 1. å‡†ç¡®ç‡è¶‹åŠ¿
    ax1 = axes[0, 0]
    ax1.plot(results_df['forecast_horizon'], results_df['accuracy'], 
             marker='o', linewidth=2, markersize=10, color='#2E86DE', label='å‡†ç¡®ç‡')
    ax1.set_xlabel('é¢„æµ‹å¤©æ•°', fontsize=12)
    ax1.set_ylabel('å‡†ç¡®ç‡', fontsize=12)
    ax1.set_title('å‡†ç¡®ç‡ vs é¢„æµ‹å¤©æ•°', fontsize=13, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    ax1.set_ylim([0.5, 1.0])
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for x, y in zip(results_df['forecast_horizon'], results_df['accuracy']):
        ax1.text(x, y + 0.02, f'{y:.1%}', ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    # 2. ç²¾ç¡®ç‡è¶‹åŠ¿
    ax2 = axes[0, 1]
    ax2.plot(results_df['forecast_horizon'], results_df['precision'], 
             marker='s', linewidth=2, markersize=10, color='#FF6348', label='ç²¾ç¡®ç‡')
    ax2.set_xlabel('é¢„æµ‹å¤©æ•°', fontsize=12)
    ax2.set_ylabel('ç²¾ç¡®ç‡', fontsize=12)
    ax2.set_title('ç²¾ç¡®ç‡ vs é¢„æµ‹å¤©æ•°', fontsize=13, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    ax2.set_ylim([0.5, 1.0])
    
    for x, y in zip(results_df['forecast_horizon'], results_df['precision']):
        ax2.text(x, y + 0.02, f'{y:.1%}', ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    # 3. å¬å›ç‡è¶‹åŠ¿
    ax3 = axes[1, 0]
    ax3.plot(results_df['forecast_horizon'], results_df['recall'], 
             marker='^', linewidth=2, markersize=10, color='#26C281', label='å¬å›ç‡')
    ax3.set_xlabel('é¢„æµ‹å¤©æ•°', fontsize=12)
    ax3.set_ylabel('å¬å›ç‡', fontsize=12)
    ax3.set_title('å¬å›ç‡ vs é¢„æµ‹å¤©æ•°', fontsize=13, fontweight='bold')
    ax3.grid(True, alpha=0.3)
    ax3.set_ylim([0.5, 1.0])
    
    for x, y in zip(results_df['forecast_horizon'], results_df['recall']):
        ax3.text(x, y + 0.02, f'{y:.1%}', ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    # 4. ç»¼åˆå¯¹æ¯”
    ax4 = axes[1, 1]
    x = np.arange(len(results_df))
    width = 0.2
    
    ax4.bar(x - width, results_df['accuracy'], width, label='å‡†ç¡®ç‡', alpha=0.8, color='#2E86DE')
    ax4.bar(x, results_df['precision'], width, label='ç²¾ç¡®ç‡', alpha=0.8, color='#FF6348')
    ax4.bar(x + width, results_df['recall'], width, label='å¬å›ç‡', alpha=0.8, color='#26C281')
    
    ax4.set_xlabel('é¢„æµ‹å¤©æ•°', fontsize=12)
    ax4.set_ylabel('æŒ‡æ ‡å€¼', fontsize=12)
    ax4.set_title('ç»¼åˆæŒ‡æ ‡å¯¹æ¯”', fontsize=13, fontweight='bold')
    ax4.set_xticks(x)
    ax4.set_xticklabels([f'{h}å¤©' for h in results_df['forecast_horizon']])
    ax4.legend(fontsize=10)
    ax4.grid(True, alpha=0.3, axis='y')
    ax4.set_ylim([0.5, 1.0])
    
    plt.tight_layout()
    
    os.makedirs('results', exist_ok=True)
    plt.savefig('results/forecast_horizon_comparison.png', dpi=300, bbox_inches='tight')
    print(f"âœ… å¯¹æ¯”å›¾å·²ä¿å­˜: results/forecast_horizon_comparison.png")
    
    plt.show()


def main():
    """
    ä¸»å‡½æ•°ï¼šå¯¹æ¯”ä¸åŒé¢„æµ‹çª—å£
    """
    from datetime import datetime
    
    print("="*80)
    print("é¢„æµ‹æ—¶é—´çª—å£å¯¹æ¯”å®éªŒ")
    print("æµ‹è¯•ä¸åŒé¢„æµ‹å¤©æ•°çš„å‡†ç¡®ç‡")
    print("="*80)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # 1. åŠ è½½æ•°æ®
    print("\næ­¥éª¤1: åŠ è½½è‚¡ç¥¨æ•°æ®")
    print("-"*60)
    
    data_path = 'data/all_stock_data.pkl'
    if not os.path.exists(data_path):
        print(f"é”™è¯¯: {data_path} ä¸å­˜åœ¨")
        print("è¯·å…ˆè¿è¡Œ: python stock_data_downloader.py")
        return
    
    with open(data_path, 'rb') as f:
        all_data = pickle.load(f)
    
    print(f"âœ… æˆåŠŸåŠ è½½ {len(all_data)} åªè‚¡ç¥¨")
    
    # 2. æµ‹è¯•ä¸åŒçš„é¢„æµ‹çª—å£
    print("\næ­¥éª¤2: æµ‹è¯•ä¸åŒé¢„æµ‹çª—å£")
    print("-"*60)
    
    horizons = [1, 3, 5, 10]  # æµ‹è¯•1å¤©ã€3å¤©ã€5å¤©ã€10å¤©
    results = []
    
    for horizon in horizons:
        result = test_single_horizon(all_data, horizon, lookback_days=60)
        if result:
            results.append(result)
    
    if not results:
        print("\nâŒ æ‰€æœ‰æµ‹è¯•éƒ½å¤±è´¥äº†")
        return
    
    # 3. æ±‡æ€»ç»“æœ
    print("\næ­¥éª¤3: æ±‡æ€»å¯¹æ¯”ç»“æœ")
    print("-"*60)
    
    results_df = pd.DataFrame(results)
    
    print("\n" + "="*80)
    print("å¯¹æ¯”ç»“æœæ±‡æ€»")
    print("="*80)
    print(results_df[['forecast_horizon', 'accuracy', 'precision', 'recall', 'f1_score']].to_string(index=False))
    
    # 4. å¯è§†åŒ–
    print("\næ­¥éª¤4: ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
    print("-"*60)
    
    visualize_comparison(results_df)
    
    # 5. ä¿å­˜ç»“æœ
    print("\næ­¥éª¤5: ä¿å­˜ç»“æœ")
    print("-"*60)
    
    os.makedirs('results', exist_ok=True)
    results_path = 'results/forecast_horizon_comparison.csv'
    results_df.to_csv(results_path, index=False, encoding='utf-8-sig')
    print(f"âœ… ç»“æœå·²ä¿å­˜: {results_path}")
    
    # 6. åˆ†æç»“è®º
    print("\næ­¥éª¤6: åˆ†æç»“è®º")
    print("-"*60)
    
    best_accuracy_idx = results_df['accuracy'].idxmax()
    best_precision_idx = results_df['precision'].idxmax()
    best_f1_idx = results_df['f1_score'].idxmax()
    
    print(f"\nğŸ“Š æ€§èƒ½æ’å:")
    print(f"  æœ€é«˜å‡†ç¡®ç‡: {results_df.loc[best_accuracy_idx, 'forecast_horizon']}å¤©å "
          f"({results_df.loc[best_accuracy_idx, 'accuracy']:.2%})")
    print(f"  æœ€é«˜ç²¾ç¡®ç‡: {results_df.loc[best_precision_idx, 'forecast_horizon']}å¤©å "
          f"({results_df.loc[best_precision_idx, 'precision']:.2%})")
    print(f"  æœ€é«˜F1åˆ†æ•°: {results_df.loc[best_f1_idx, 'forecast_horizon']}å¤©å "
          f"({results_df.loc[best_f1_idx, 'f1_score']:.2%})")
    
    # æ€§èƒ½è¡°å‡åˆ†æ
    if len(results_df) > 1:
        first_acc = results_df.iloc[0]['accuracy']
        last_acc = results_df.iloc[-1]['accuracy']
        acc_decay = (first_acc - last_acc) / first_acc
        
        print(f"\nğŸ“‰ å‡†ç¡®ç‡è¡°å‡:")
        print(f"  {results_df.iloc[0]['forecast_horizon']}å¤©: {first_acc:.2%}")
        print(f"  {results_df.iloc[-1]['forecast_horizon']}å¤©: {last_acc:.2%}")
        print(f"  è¡°å‡å¹…åº¦: {acc_decay:.2%}")
    
    # æ¨èé…ç½®
    print(f"\nğŸ’¡ æ¨èé…ç½®:")
    best_horizon = results_df.loc[best_accuracy_idx, 'forecast_horizon']
    
    if best_horizon <= 1:
        print(f"  âœ… {best_horizon}å¤©é¢„æµ‹å‡†ç¡®ç‡æœ€é«˜")
        print(f"  é€‚åˆ: æ—¥å†…äº¤æ˜“ã€çŸ­çº¿æ“ä½œ")
        print(f"  ç‰¹ç‚¹: å‡†ç¡®ç‡é«˜ä½†éœ€é¢‘ç¹äº¤æ˜“")
    elif best_horizon <= 3:
        print(f"  âœ… {best_horizon}å¤©é¢„æµ‹æ•ˆæœå¾ˆå¥½")
        print(f"  é€‚åˆ: çŸ­çº¿äº¤æ˜“")
        print(f"  ç‰¹ç‚¹: å‡†ç¡®ç‡é«˜ä¸”äº¤æ˜“é¢‘ç‡é€‚ä¸­")
    elif best_horizon <= 5:
        print(f"  âœ… {best_horizon}å¤©é¢„æµ‹å¹³è¡¡æ€§å¥½")
        print(f"  é€‚åˆ: æ³¢æ®µäº¤æ˜“ï¼ˆæ¨èï¼‰")
        print(f"  ç‰¹ç‚¹: è¿‡æ»¤å™ªéŸ³ï¼Œç¬¦åˆT+1è§„åˆ™")
    else:
        print(f"  âœ… {best_horizon}å¤©é¢„æµ‹ç¨³å®š")
        print(f"  é€‚åˆ: ä¸­çº¿æŠ•èµ„")
        print(f"  ç‰¹ç‚¹: æ•æ‰ä¸­æœŸè¶‹åŠ¿")
    
    print(f"\nå®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)


if __name__ == '__main__':
    main()
